{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167b14c5-f8a5-4e8d-a6a8-988b338a7f71",
   "metadata": {},
   "source": [
    "# Relevant code for the projects\n",
    "\n",
    "The following snippets of code perform some of the basic operations required for the projects.\n",
    "\n",
    "Feel free to modify them, or to use alternative solutions, when you include them in your exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b28b9c-4e29-4580-a208-56db1f07c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading some relevant librarires\n",
    "# Note: the installation of the libraries follows the same instruction as the radar exercise\n",
    "import csv\n",
    "import datetime\n",
    "import scipy\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e46a6-ea8b-4221-a529-161fde2ff7a2",
   "metadata": {},
   "source": [
    "## 1. Loading variables from a NetCDF file\n",
    "\n",
    "Many of the data files provided for the project are in the NetCDF format.\n",
    "The following lines of code will allnetCDF4 to open the files, list the available variables, and store one (or more) of them in a numpy array.\n",
    "\n",
    "**Note:** from the code below, only the four arrays defined at the end will be available for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb967d-3eb7-4543-a7f1-a3e70291b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example file from the ERA5 reanalysis\n",
    "input_netcdf_filepath = './Example_data_project/crete_20210709.nc'\n",
    "\n",
    "# Opening the file using \"with\":\n",
    "# The file will be opened and the content is stored in a variable, that we named \"input_netcdf_f\".\n",
    "# The file will be closed and the variable \"input_netcdf_f\" will be deleted once we are outside the indented block.\n",
    "# We can store all the variables and dimension that we need in numpy arrays, which will be available outside the indented block.\n",
    "with nc.Dataset(input_netcdf_filepath) as input_netcdf_f:\n",
    "    # Let's see what's inside the file:\n",
    "    # 1) dimensions\n",
    "    dimension_list = input_netcdf_f.dimensions.keys()\n",
    "    # 2) variables\n",
    "    variable_list = input_netcdf_f.variables.keys()\n",
    "    print('Dimensions:\\n', dimension_list)\n",
    "    print('Variables:\\n', variable_list)\n",
    "    \n",
    "    # If you're curious about a variable, you can show the information avaialble on it\n",
    "    chosen_var_name = 't2m'\n",
    "    chosen_var_content = input_netcdf_f[chosen_var_name]\n",
    "    print('\\nInfo about %s:\\n' % chosen_var_name, chosen_var_content)\n",
    "    \n",
    "    # We can also print some basic information (mostly size) on dimensions\n",
    "    dimension_time = input_netcdf_f.dimensions['time']\n",
    "    dimension_lat = input_netcdf_f.dimensions['latitude']\n",
    "    dimension_lon = input_netcdf_f.dimensions['longitude']\n",
    "    print('\\nInfo about time (as dimensions):\\n', dimension_time)\n",
    "    print('Info about latitude (as dimensions):\\n', dimension_lat)\n",
    "    print('Info about longitude (as dimensions):\\n', dimension_lon)\n",
    "    \n",
    "    # The values for each dimensions are also stored as variables, let us access and display them\n",
    "    variable_time = input_netcdf_f.variables['time']\n",
    "    variable_lat = input_netcdf_f.variables['latitude']\n",
    "    variable_lon = input_netcdf_f.variables['longitude']\n",
    "    print('\\nInfo about time (as variable):\\n', variable_time)\n",
    "    print('\\nInfo about latitude (as variable):\\n', variable_lat)\n",
    "    print('\\nInfo about longitud (as variable)e:\\n', variable_lon)\n",
    "    \n",
    "    # Let us now store the variables that we need in numpy arrays.\n",
    "    # These arrays will be available outside the current indented block (while the variable \"input_netcdf_f\" will not).\n",
    "    time_array = np.array(variable_time)\n",
    "    lat_array = np.array(variable_lat)\n",
    "    lon_array = np.array(variable_lon)\n",
    "    t2m_array = np.array(input_netcdf_f['t2m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b7f21-d08f-4b07-95c5-8e69c63c57dd",
   "metadata": {},
   "source": [
    "## 2. Displaying the variables\n",
    "We will use the library \"matplotlib\" to visualize the 2 meter temperature that we extracted from the file.\n",
    "\n",
    "Since we extracted 3 dimensions (time, latitude, longitude), we will have to select 1 or 2 of them to act as coordinates for plotting the temperature.\n",
    "We will show how to make two tipes of plots:\n",
    "- after fixing a specific time step, we can visualize a map of the temperature over a latitude/longitude grid\n",
    "- after fixing a specific location in space, we can visualize how temperature changes in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d944c-621a-4f2b-9eaa-f8f7a0d5b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first of the two plots we produce is the map of temperature for a specific time step.\n",
    "# Let's see what time steps are available\n",
    "print('Available time steps: ', time_array)\n",
    "\n",
    "# In this case, the time steps are stored as hours since 1900-01-01 00:00 (as explained by the information about the \"time variable\" printed previouly)\n",
    "# Let us convert the values in a more easily readable format, using the \"datetime\" library\n",
    "# As a starting point, we can convert a single value of the time_array to a readable format is we sum its values in hours to the reference start date of 1900-01-01\n",
    "reference_start_date = datetime.datetime(1900, 1, 1, 0, 0) # <- the reference start date of 1900-01-01\n",
    "first_time_steps_as_hour_difference = datetime.timedelta(hours = int(time_array[0])) # <- the time difference in hours\n",
    "first_time_step = reference_start_date + first_time_steps_as_hour_difference\n",
    "print('The first entry in the time array correspond to the date and time: ', first_time_step)\n",
    "# We can repeat the process for all entry in the array, using a \"for\" loop\n",
    "time_array_converted = [reference_start_date + datetime.timedelta(hours=int(t)) for t in time_array]\n",
    "print('All the available date and time steps are:\\n', time_array_converted)\n",
    "\n",
    "# Let's pick a time step for our analysis. For this example, let's pick the 2022-07-09 at 12:00, which is the fifth entry in the time array.\n",
    "chosen_time_index = 4 \n",
    "chosen_date_time = time_array_converted[chosen_time_index]\n",
    "\n",
    "# When we displayed the information available on the temperature variables, we saw that its dimensions are (time, latitude, longitude).\n",
    "# Therefore, to select the first time step, we will have to select the time index across the first dimension of the array\n",
    "t2m_at_chosen_time = t2m_array[chosen_time_index, :, :]\n",
    "print('\\nAt the chosen time step, the temperature array has the following shape: ', t2m_at_chosen_time.shape, '\\n')\n",
    "\n",
    "# At a fixed time step, the temperature array has 2 dimensions: latitude and longitude.\n",
    "# We can visualize how the 2-meter temperature varies across space in a map, with latitude and longitude on the x and y axis of a figure.\n",
    "# Let's first create the figure and the axis\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes()\n",
    "\n",
    "# Let us chose a colormap for the temperature\n",
    "# You can find a list of colormaps at: https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "cmap = 'plasma'\n",
    "\n",
    "# To visualize 2-dimensional maps, we can use \"pcolormesh\"\n",
    "mappable = ax.pcolormesh(lon_array, lat_array, t2m_at_chosen_time, cmap=cmap) # <- we added a \".T\" to the temperature array to transpose it, since we want the longitude on the x-axis\n",
    "\n",
    "# We can add information to the map in the form of labels and a title\n",
    "ax.set_xlabel('Longitude [°]')\n",
    "ax.set_ylabel('Latitude [°]')\n",
    "ax.set_title('2-meter temperature at %s' % chosen_date_time.strftime('%Y-%m-%d %H:%M')) # <- \"strftime\" is a function to format the date/time in a custom string\n",
    "\n",
    "# To see what color correspond to each temperature value, we can display a colorbar\n",
    "plt.colorbar(mappable=mappable, label='Temperature [K]')\n",
    "pass # <- we add it just that so jupyter does not write colorbar (i.e. the last command we called) info at screen, which can be distracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da086ab5-40ea-4713-b088-02dbb799e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try to make the figure more \"understandable\" by:\n",
    "# - adding the coastlines\n",
    "# - showing the temperature in degree Celsius\n",
    "\n",
    "# Converting the temperature in Celsius\n",
    "t2m_celsius_at_chosen_time = t2m_at_chosen_time - 273.15\n",
    "\n",
    "# Let's create a new figure\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree()) # <- to display the coastline, we need to define a gregraphic projection\n",
    "\n",
    "# Same steps as before for displaying the data\n",
    "cmap = 'plasma'\n",
    "mappable = ax.pcolormesh(lon_array, lat_array, t2m_celsius_at_chosen_time, cmap=cmap)\n",
    "ax.set_title('2-meter temperature at %s' % chosen_date_time.strftime('%Y-%m-%d %H:%M'))\n",
    "\n",
    "# We can visualize the coastiline above the data (since we defined a projection when creating the axis)\n",
    "ax.coastlines(color='green', linewidth=1.6)\n",
    "\n",
    "# Unfortunately cartopy, which allows us to see the coastline, will disable the functions that control the axis labels.\n",
    "# We need to use instead a function that is defined in cartopy, that provides gridlines and labels for the axis.\n",
    "# More information on the function available at: https://scitools.org.uk/cartopy/docs/latest/matplotlib/gridliner.html\n",
    "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linestyle=':', linewidth=1.5, color='gray', alpha=0.6)\n",
    "\n",
    "# Let's remember to change the label of the colorbar!\n",
    "plt.colorbar(mappable=mappable, label='Temperature [°C]', pad=0.1) # <- we added a \"pad\" parameter to move a bit the colorbar to the right, otherwise it overlaps with the labels\n",
    "pass # <- we add it just that so jupyter does not write colorbar (i.e. the last command we called) info at screen, which can be distracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c74fb-1e02-407f-aa5b-32809a8f471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now move to the next topic: how to display a varibale at a single point for multiple time steps.\n",
    "\n",
    "# Let us select a set of coordinates.\n",
    "# First, let's see the range of latitude and longitude\n",
    "print('Longitude varies between %.1f and %.1f degrees East' % (lon_array.min(), lon_array.max()))\n",
    "print('Laztitude varies between %.1f and %.1f degrees East' % (lat_array.min(), lat_array.max()))\n",
    "# The full set of values for each coordinate can be displayed as follows:\n",
    "print('\\nAll longitude values available: ', lon_array)\n",
    "print('\\nAll latitude values available: ', lat_array)\n",
    "\n",
    "# In this case we have few values, so we can select them manually by counting the index.\n",
    "# Let's say we want to choose the point with lon=21.5 and lat = 35.25, we would simply count the index (starting from 0 at the first place in the array), and obtain:\n",
    "i_lon = 2\n",
    "j_lat = 7\n",
    "# And we could use these indexes to select a time-series of temperature at that point.\n",
    "# Remembering that the dimension of the 2-meter temperature variable are (time, latitude, longitude), we know that the two indexes will occupy the last two poistions:\n",
    "time_series_t2m = t2m_array[:, j_lat, i_lon]\n",
    "# And we can check how many time steps we have available for the analysis at this point:\n",
    "print('At the coordinates (lat=%.1f, lon=%.1f), the 2-meter temperature array has the following shape: ' % (lat_array[j_lat], lon_array[i_lon]), time_series_t2m.shape) \n",
    "\n",
    "# However, if you have a large number of points in your lat/lon grid, it may be difficult to select and index manually.\n",
    "# If you know the coordinates of the point you want to look at, you can find the oint of the grid closest to your desired point.\n",
    "\n",
    "# Let's say you want to look at the point closest to Heraklion, the administrative capital of the island of Crete.\n",
    "# Its coordinates in decimal units are:\n",
    "lon_desired = 25.134444\n",
    "lat_desired = 35.340278 # source: https://geohack.toolforge.org/geohack.php?pagename=Heraklion&params=35_20_25_N_25_8_4_E_region:GR_type:city(173993)\n",
    "\n",
    "# The indexes in our lat and lon array closest to these points are:\n",
    "i_lon_heraklion = np.argmin(np.abs(lon_array - lon_desired)) # <- basically the minimum of the absolute difference in longitude\n",
    "j_lat_heraklion = np.argmin(np.abs(lat_array - lat_desired))\n",
    "print('\\nThe closest indices of our lat/lon grid to the coordinates of Heraklion are: ', i_lon_heraklion, j_lat_heraklion)\n",
    "print('These indexes correspond to: latitude = %f, longitude = %f\\n' % (lat_array[j_lat_heraklion], lon_array[i_lon_heraklion]))\n",
    "\n",
    "# We can now extract a time series above this grid point\n",
    "time_series_t2m_Heraklion = t2m_array[:, j_lat_heraklion, i_lon_heraklion]\n",
    "# Let's convert it to Celsius\n",
    "time_series_t2m_celsius_Heraklion = time_series_t2m_Heraklion - 273.15\n",
    "\n",
    "# We can now visualize this time series in a figure\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = plt.axes()\n",
    "\n",
    "# To plot one variable against another (in our case, temperature at 1 grid point vs time), we use the \"plot\" function\n",
    "# We use the array of time steps converted to \"datetime\" format that we defined before, and put it on the x-axis\n",
    "ax.plot(time_array_converted, time_series_t2m_celsius_Heraklion, marker='.', color='tab:red')\n",
    "\n",
    "# As before, we add information to the plot in form of axis and labels\n",
    "ax.set_xlabel('Date and time')\n",
    "ax.set_ylabel('Temperature [°C]')\n",
    "ax.set_title('2-meter temperature above Heraklion')\n",
    "\n",
    "# We can also add a grid, and put it below the plot line\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(ls=':', c='gray', alpha=0.5)\n",
    "\n",
    "# Since the automatic formatting on the x-axis can be a bit weird, we can manually define one:\n",
    "date_format_xaxis = mdates.DateFormatter('%d-%m-%Y\\n%H:%M')\n",
    "ax.xaxis.set_major_formatter(date_format_xaxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6891e4ca-bd0f-4ac9-831c-0309aa0d2706",
   "metadata": {},
   "source": [
    "## 3. Performing simple statistics with the variables\n",
    "\n",
    "We will use some functions from the numpy library to:\n",
    "- extract specific regions from the 2-meter temperature field\n",
    "- compute simple statistics on these values, to summarize the information within each region\n",
    "- perform a simple comparison between the 2-meter temperature values in two different regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e899f4-e4bf-4d26-8d5a-ac3cd41d5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the previous section we have worked arrays with a reduced number of dimensions: we either fixed the time, or the lat-lon coordinates.\n",
    "# This time, we will work with the full 3-dimensional (time, latitude, longitude) array.\n",
    "\n",
    "# In the current example, our objective is to extract the 2-meter temperature from 2 different regions of the map.\n",
    "# These regions are:\n",
    "# - the cluster of small island in the top (north) of the map, between the peloponnese and souther anatolia;\n",
    "# - the sea in the bottom-left (south-west) corner of the map, above the eastern side of Libya.\n",
    "\n",
    "# To extract the regions, we first need to define their boundaries:\n",
    "# - the island region to the north\n",
    "min_lat_region_islands = 36.0 # The limit to the south\n",
    "max_lat_region_islands = 37.0 # north\n",
    "min_lon_region_islands = 24.0 # west\n",
    "max_lon_region_islands = 27.0 # east\n",
    "# - the sea region to the south-west\n",
    "min_lat_region_sea = 33.0 # south\n",
    "max_lat_region_sea = 34.0 # north\n",
    "min_lon_region_sea = 21.0 # west\n",
    "max_lon_region_sea = 24.0 # east\n",
    "\n",
    "# Before defining the region, we need to create a couple of 2-dimensional array, which contain the latitude and longitude values in a grid.\n",
    "lon_2d, lat_2d = np.meshgrid(lon_array, lat_array)\n",
    "print('The size of the 2-dimensional latitude and longitude arrays are: ', lat_2d.shape, lon_2d.shape)\n",
    "# Note that the sizes printed above are the same as the 2-meter temperature array at a singe time step (the one we showed before in the map).\n",
    "\n",
    "# With the boundaries, we can now define a set of boolean conditions. These will be two 2-dimensional array, one for each region, having the values:\n",
    "# - \"True\" at the indices of the array that are within the region\n",
    "# - \"False\" for the ones outside.\n",
    "conditions_within_region_islands = np.logical_and(np.logical_and(lon_2d >= min_lon_region_islands, lon_2d <= max_lon_region_islands),\n",
    "                                                  np.logical_and(lat_2d >= min_lat_region_islands, lat_2d <= max_lat_region_islands)) # (note that when you're within parenthesis, the code can continue at the next line)\n",
    "print('\\nThe islands region contains %d points. The size of the boolean array that contains the conditions is: ' % conditions_within_region_islands.sum(), conditions_within_region_islands.shape)\n",
    "conditions_within_region_sea = np.logical_and(np.logical_and(lon_2d >= min_lon_region_sea, lon_2d <= max_lon_region_sea),\n",
    "                                                  np.logical_and(lat_2d >= min_lat_region_sea, lat_2d <= max_lat_region_sea)) # (note that when you're within parenthesis, the code can continue at the next line)\n",
    "print('The sea region contains %d points. The size of the boolean array that contains the conditions is: ' % conditions_within_region_sea.sum(), conditions_within_region_sea.shape)\n",
    "\n",
    "# We can see how many latitude and longitude points are within each region, by summing its content along the two axes.\n",
    "# (in a sum, boolean values are treated as integers: True becomes 1, False becomes 0)\n",
    "# Since we are working with rectangular regions, we can just pick the maximum value of the sum\n",
    "num_valid_lon_islands_region = np.sum(conditions_within_region_islands, axis = 1).max()\n",
    "num_valid_lat_islands_region = np.sum(conditions_within_region_islands, axis = 0).max()\n",
    "print('\\nNumber of valid latitudes in the island region: ', num_valid_lat_islands_region)\n",
    "print('Number of valid longitudes in the island region: ', num_valid_lon_islands_region)\n",
    "num_valid_lon_sea_region = np.sum(conditions_within_region_sea, axis = 1).max()\n",
    "num_valid_lat_sea_region = np.sum(conditions_within_region_sea, axis = 0).max()\n",
    "print('\\nNumber of valid latitudes in the sea region: ', num_valid_lat_sea_region)\n",
    "print('Number of valid longitudes in the sea region: ', num_valid_lon_sea_region, '\\n')\n",
    "\n",
    "# We can use these two conditions matrices for simply extracting the temperature values, without performing any statistics (for the moment)\n",
    "# The first step is the creation of empty arrays to store the 2-meter temperature value of each region.\n",
    "# We will use \"nan\" (= not a number) values to denote empty positions in the array\n",
    "t2m_islands_region = np.full((time_array.shape[0], num_valid_lat_islands_region, num_valid_lon_islands_region), np.nan)\n",
    "# We can fill the empty container by looping over time\n",
    "for index_time in range(time_array.shape[0]):\n",
    "    # At each time step, we select the 2-meter temperature from the whole map at that time step\n",
    "    t2m_at_current_time = t2m_array[index_time, :]\n",
    "    # And we assign this value to the container at the same time step\n",
    "    t2m_islands_region[index_time, :] = t2m_at_current_time[conditions_within_region_islands].reshape(num_valid_lat_islands_region, num_valid_lon_islands_region)\n",
    "\n",
    "# And we repeat the procedure for the sea region\n",
    "t2m_sea_region = np.full((time_array.shape[0], num_valid_lat_sea_region, num_valid_lon_sea_region), np.nan)\n",
    "for index_time in range(time_array.shape[0]):\n",
    "    t2m_at_current_time = t2m_array[index_time, :]\n",
    "    t2m_sea_region[index_time, :] = t2m_at_current_time[conditions_within_region_sea].reshape(num_valid_lat_sea_region, num_valid_lon_sea_region)\n",
    "\n",
    "# Let us visualize the regions that we extracted.\n",
    "# Since we have a 2-dimensional array at each time step, we have to select a specific time step for the plot.\n",
    "# Let's select the same one we used in the previous example, so we can compare the temperature value to make sure that we selected the correct regions.\n",
    "t2m_islands_region_at_chosen_time = t2m_islands_region[chosen_time_index, :, :]\n",
    "t2m_sea_region_at_chosen_time = t2m_sea_region[chosen_time_index, :, :]\n",
    "# We also conver them to Celsius\n",
    "t2m_celsius_islands_region_at_chosen_time = t2m_islands_region_at_chosen_time - 273.15\n",
    "t2m_celsius_sea_region_at_chosen_time = t2m_sea_region_at_chosen_time - 273.15\n",
    "\n",
    "# We also need to define the lat and lon array for the two regions, so that we have the coordinates for the plot\n",
    "lon_2d_islands_region = lon_2d[conditions_within_region_islands].reshape(num_valid_lat_islands_region, num_valid_lon_islands_region)\n",
    "lat_2d_islands_region = lat_2d[conditions_within_region_islands].reshape(num_valid_lat_islands_region, num_valid_lon_islands_region)\n",
    "lon_2d_sea_region = lon_2d[conditions_within_region_sea].reshape(num_valid_lat_sea_region, num_valid_lon_sea_region)\n",
    "lat_2d_sea_region = lat_2d[conditions_within_region_sea].reshape(num_valid_lat_sea_region, num_valid_lon_sea_region)\n",
    "\n",
    "# Creating the figure as before\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree()) # <- same gregraphic projection\n",
    "cmap = 'plasma'\n",
    "\n",
    "# SInce the two regions are displayed independently, to ensure that the colorbar is the same between the two, we have to decide manually the limits\n",
    "t2m_min_in_plot = 22 # deg. Celsius\n",
    "t2m_max_in_plot = 32 # deg. Celsius\n",
    "\n",
    "# We have to call the \"pcolormesh\" function twice, once for each region\n",
    "mappable = ax.pcolormesh(lon_2d_islands_region, lat_2d_islands_region, t2m_celsius_islands_region_at_chosen_time, cmap=cmap, vmin=t2m_min_in_plot, vmax=t2m_max_in_plot)\n",
    "mappable = ax.pcolormesh(lon_2d_sea_region, lat_2d_sea_region, t2m_celsius_sea_region_at_chosen_time, cmap=cmap, vmin=t2m_min_in_plot, vmax=t2m_max_in_plot)\n",
    "\n",
    "# Adding the same extra info as before\n",
    "ax.set_title('2-m temperature in selected regions at %s' % chosen_date_time.strftime('%Y-%m-%d %H:%M'))\n",
    "ax.coastlines(color='green', linewidth=1.6)\n",
    "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linestyle=':', linewidth=1.5, color='gray', alpha=0.6)\n",
    "plt.colorbar(mappable=mappable, label='Temperature [°C]', pad=0.1)\n",
    "pass # <- we add it just that so jupyter does not write colorbar (i.e. the last command we called) info at screen, which can be distracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99685d18-55eb-433c-ada2-fe3fa6ad24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the regions, we can extract some statistics from them, to summarize the information at each time steps.\n",
    "# For this example, we will extract the mean and standard deviation.\n",
    "# Other possible statistics (e.g. median, quantile) are available in the numpy library, if you want to use them in your project you can find them here: https://numpy.org/doc/stable/reference/routines.statistics.html \n",
    "# Since our arrays contain \"nan\" values, we have to use functions that can handle them safely. For instance, \"numpy.nanmean\" instead of \"numpy.mean\".\n",
    "\n",
    "# Luckily for us, the numpy functions can compute statistics on multiple axis at once:\n",
    "mean_t2m_islands_region = np.nanmean(t2m_islands_region, axis=(1,2)) # <- averages over axis 1 and 2, which are latitude and longitude\n",
    "mean_t2m_sea_region = np.nanmean(t2m_sea_region, axis=(1,2))\n",
    "print('Shape of the array containing the mean 2-meter temperature in the islands region: ', mean_t2m_islands_region.shape)\n",
    "print('Shape of the array containing the mean 2-meter temperature in the sea region: ', mean_t2m_sea_region.shape, '\\n')\n",
    "std_t2m_islands_region = np.nanstd(t2m_islands_region, axis=(1,2))\n",
    "std_t2m_sea_region = np.nanstd(t2m_sea_region, axis=(1,2))\n",
    "print('Shape of the array containing the standard deviation of the 2-meter temperature in the islands region: ', std_t2m_islands_region.shape)\n",
    "print('Shape of the array containing the standard deviation of the 2-meter temperature in the sea region: ', std_t2m_sea_region.shape, '\\n')\n",
    "\n",
    "# We can now display how the mean and standard deviation for the 2 regions varies in time.\n",
    "# This time, we will create a figure with multiple panels:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Let us define two different colors, one for each region\n",
    "color_islands = 'tab:red'\n",
    "color_sea = 'tab:blue'\n",
    "\n",
    "# Let us convert again the temperature to Celsius\n",
    "mean_t2m_celsius_islands_region = mean_t2m_islands_region - 273.15\n",
    "mean_t2m_celsius_sea_region = mean_t2m_sea_region - 273.15\n",
    "\n",
    "# On the first axis we show the mean\n",
    "ax0 = axes[0]\n",
    "# As in the previous figure, we call the plotting function twice, once for each region\n",
    "ax0.plot(time_array_converted, mean_t2m_celsius_islands_region, marker='^', color=color_islands, label='Islands region') # <- the label will be used in the legend\n",
    "ax0.plot(time_array_converted, mean_t2m_celsius_sea_region, marker='.', color=color_sea, label='Sea region')\n",
    "# We can create a legend, that helps us to distinguish between the two curves\n",
    "ax0.legend()\n",
    "\n",
    "# As before, we fnish up the plot with some formatting\n",
    "ax0.set_xlabel('Time')\n",
    "ax0.set_ylabel('Temperature [°C]')\n",
    "ax0.set_title('Mean 2-meter temperature')\n",
    "ax0.set_axisbelow(True)\n",
    "ax0.grid(ls=':', c='gray', alpha=0.5)\n",
    "date_format_xaxis = mdates.DateFormatter('%H:%M')\n",
    "ax0.xaxis.set_major_formatter(date_format_xaxis)\n",
    "\n",
    "# On the second axis we show the standard deviation\n",
    "ax1 = axes[1]\n",
    "\n",
    "ax1.plot(time_array_converted, std_t2m_islands_region, marker='^', color=color_islands, label='Islands region') # <- the label will be used in the legend\n",
    "ax1.plot(time_array_converted, std_t2m_sea_region, marker='.', color=color_sea, label='Sea region')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Temperature [°C]')\n",
    "ax1.set_title('Standard deviation of the 2-meter temperature')\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.grid(ls=':', c='gray', alpha=0.5)\n",
    "ax1.xaxis.set_major_formatter(date_format_xaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554a413-d53d-43b5-ac79-c11ab42070a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can display these types of results in a more compact way.\n",
    "# This function allow us to show the standard deviation around the mean as an errorbar:\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.errorbar.html\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "\n",
    "# Same colors as before\n",
    "color_islands = 'tab:red'\n",
    "color_sea = 'tab:blue'\n",
    "\n",
    "# the function requires the length of the bar along each axis. We will only show a bar on the y axis, around each point, representing the standard deviation\n",
    "ax.errorbar(time_array_converted, mean_t2m_celsius_islands_region, yerr=std_t2m_islands_region, color=color_islands, capsize=2., label='Islands region') \n",
    "ax.errorbar(time_array_converted, mean_t2m_celsius_sea_region, yerr=std_t2m_sea_region, color=color_sea, capsize=2., label='Sea region')\n",
    "ax.legend()\n",
    "\n",
    "# As before, we fnish up the plot with some formatting\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Temperature [°C]')\n",
    "ax.set_title('Mean and standard deviation of the 2-meter temperature')\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(ls=':', c='gray', alpha=0.5)\n",
    "ax.xaxis.set_major_formatter(date_format_xaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d883cb-9582-46e8-a835-cadfa77dd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the trends of the two mean temperature is not the only way to compare them.\n",
    "# For example, we can make a scatterplot of the two mean temperatures.\n",
    "# The structure of the plot is similar to the other ones we made, but we will use a different plotting function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "\n",
    "# We can inpose that the two axis have equal units\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# the function requires the length of the bar along each axis. We will only show a bar on the y axis, around each point, representing the standard deviation\n",
    "ax.scatter(mean_t2m_celsius_islands_region, mean_t2m_celsius_sea_region, marker='.', color='tab:purple')\n",
    "\n",
    "# As before, we fnish up the plot with some formatting\n",
    "ax.set_xlabel('Mean temperature islands region [°C]')\n",
    "ax.set_ylabel('Mean temperature sea region [°C]')\n",
    "ax.set_title('Scatteplot of 2-meter temperature over the two regions')\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(ls=':', c='gray', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f691431-c071-4813-b57a-a8c004f3fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The points in the previous plot look quite aligned! Let's see what a linear regression between the two sets gives us.\n",
    "# We will use the scipy library for this task.\n",
    "# Many other functions (beside the linear regression) are available in scipy, you can have a look at them here: https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n",
    "# The function is very easy to use: given a series of x (in our case, the mean 2-m temperature over the islands) and y (mean 2-m temperature over the sea), it returns the following information:\n",
    "# - slope = the slope of the regression line;\n",
    "# - intercept = the intercept of the regression line;\n",
    "# - r_value = the Pearson correlation coefficient;\n",
    "# - p_value = the p-value for a hypothesis test whose null hypothesis is that the slope is zero, using Wald Test with t-distribution of the test statistic (alternative tests can be performed);\n",
    "# - std_error = the standard error of the estimated slope (gradient), under the assumption of residual normality.\n",
    "slope, intercept, r, p, se = scipy.stats.linregress(mean_t2m_celsius_islands_region, mean_t2m_celsius_sea_region)\n",
    "\n",
    "# First, we can print these values:\n",
    "print('Linear regression between the mean 2-m temperature over the island region and the 2-temperature over the sea region.')\n",
    "print('Slope: ', slope)\n",
    "print('Intercept: ', intercept)\n",
    "print('Pearson correlation coefficient: ', r)\n",
    "print('p-value: ', p)\n",
    "print('Standard error of the estimated slope: ', se, '\\n')\n",
    "\n",
    "# We can visualize the curve associated to the computed slope and intercept over the scatterplot we produced in the previous figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "# BuPlottig first the fitted line, so it appears \"below\" the points\n",
    "# We first define an array \"x\" that contains the values on the x-axis in order\n",
    "x_array_for_plotting_fit = np.sort(mean_t2m_celsius_islands_region)\n",
    "ax.plot(x_array_for_plotting_fit, intercept + slope*x_array_for_plotting_fit, 'tab:orange', ls='--', label='Fitted line')\n",
    "\n",
    "# Plotting the points exactly as before\n",
    "ax.scatter(mean_t2m_celsius_islands_region, mean_t2m_celsius_sea_region, marker='.', color='tab:purple', label='Original data')\n",
    "\n",
    "# And we add a legend\n",
    "ax.legend()\n",
    "\n",
    "# As before, we fnish up the plot with some formatting\n",
    "ax.set_xlabel('Mean temperature islands region [°C]')\n",
    "ax.set_ylabel('Mean temperature sea region [°C]')\n",
    "ax.set_title('Scatteplot of 2-meter temperature over the two regions')\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(ls=':', c='gray', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c4cd6-f3e7-47bf-8a40-e20e847e2770",
   "metadata": {},
   "source": [
    "# 4. Loading variable from CSV files\n",
    "\n",
    "Another file format that you can encounter while doing your project is the CSV.\n",
    "Luckily, python has a library dedicated to these files.\n",
    "\n",
    "Here we will open two example CSV files:\n",
    "- the first one will contain the coordinates of some rain gauges,\n",
    "- the second one contains the data collected by these gauges at differnet time steps.\n",
    "\n",
    "After opening the files, we will load their contend and perform simple operations on their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbefcd8-1475-4146-a520-7658b6022ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loading of CSV files can be performed in a way similar to the procedure we followed for the NetCDF files. \n",
    "# First, we define the path to the first CSV file\n",
    "input_csv_measurements_filepath = './Example_data_project/example_measurements.csv'\n",
    "\n",
    "# We will store the data and the locations in a new type of object, called ordered dictionary.\n",
    "# You can read more about ordered dictionaries here: https://docs.python.org/3/library/collections.html#ordereddict-objects\n",
    "csv_measurements_dictionary = OrderedDict()\n",
    "\n",
    "# Opening the first file file using \"with\":\n",
    "with open(input_csv_measurements_filepath) as csv_measurements:\n",
    "    # We define a csv.reader, with the character \",\" as delimiter between entries\n",
    "    csv_measurements_reader = csv.reader(csv_measurements, delimiter=',')\n",
    "    \n",
    "    # Let's loop over the first 6 rows and see what's inside the file\n",
    "    print('Content of the first five rows:\\n')\n",
    "    for idx_row, measurements_row in enumerate(csv_measurements_reader):\n",
    "        print(', '.join(measurements_row))\n",
    "        if idx_row > 4:\n",
    "            break\n",
    "            \n",
    "    # Returning at the beginnin of the file\n",
    "    csv_measurements.seek(0)\n",
    "    \n",
    "    # Now we loop over all the row of data, and separate comments, header and actual measurements\n",
    "    for measurements_row in csv_measurements_reader:\n",
    "        # Here we separate the rows in three categories:\n",
    "        if measurements_row[0].startswith('#'):\n",
    "            # Excluding rows that start with the chraracter \"#\" (comments)\n",
    "            continue\n",
    "        elif measurements_row[0] == 'TIMESTAMP':\n",
    "            # The header in our case start with the string \"TIMESTAMP\"\n",
    "            header_measurement_file = measurements_row\n",
    "            # We use this header to define the entries in our dictionary\n",
    "            for header_entry in measurements_row:\n",
    "                csv_measurements_dictionary[header_entry] = []\n",
    "        else:\n",
    "            # The remaining rows contain data\n",
    "            for idx_in_row, current_measurement in enumerate(measurements_row):\n",
    "                if current_measurement == '':\n",
    "                    # Empty measurements will be stored as \"nan\" (= not a number)\n",
    "                    csv_measurements_dictionary[header_measurement_file[idx_in_row]].append(np.nan)\n",
    "                else:\n",
    "                    # Otherwise, we convert the string that we have read to a floating point number\n",
    "                    csv_measurements_dictionary[header_measurement_file[idx_in_row]].append(float(current_measurement))\n",
    "\n",
    "# Let's have a look at our dictionary of measurements\n",
    "print('\\nKeys of the measurment dictionary:', list(csv_measurements_dictionary.keys()))\n",
    "print('Measurements at the AIE station:', csv_measurements_dictionary['AIE'])\n",
    "print('Measurements at the AGSTE station:', csv_measurements_dictionary['AGSTE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28359224-d0e2-46b6-b6be-63aa21a75b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the procedure for the CSV file that contains the locations\n",
    "# We define its path:\n",
    "input_csv_locations_filepath = './Example_data_project/example_locations.csv'\n",
    "# And the \"container\" for the data\n",
    "csv_locations_dictionary = OrderedDict()\n",
    "\n",
    "# Again we use \"with\" to open the file\n",
    "with open(input_csv_locations_filepath) as csv_locations:\n",
    "    csv_locations_reader = csv.reader(csv_locations, delimiter=',')\n",
    "    \n",
    "    # And again we loop over the first 6 rows and see what's inside the file\n",
    "    print('Content of the first five rows:\\n')\n",
    "    for idx_row, locations_row in enumerate(csv_locations_reader):\n",
    "        print(', '.join(locations_row))\n",
    "        if idx_row > 4:\n",
    "            break\n",
    "    csv_locations.seek(0)\n",
    "            \n",
    "    # We see that this time the station names are on the rows, so the storage of the file content will be slightly different\n",
    "    for locations_row in csv_locations_reader:\n",
    "        if locations_row[0] == 'Abbrev':\n",
    "            # We skip the header row\n",
    "            continue\n",
    "        else:\n",
    "            # We store the value of the coordinates in a small dictionary\n",
    "            current_location = OrderedDict()\n",
    "            current_location['Y'] = locations_row[1]\n",
    "            current_location['X'] = locations_row[2]\n",
    "            current_location['Z'] = locations_row[3]\n",
    "            # And this dictionary is stored at the entry denoted by the station name\n",
    "            csv_locations_dictionary[locations_row[0]]  = current_location\n",
    "            \n",
    "# Let's have a look at our dictionary of locations\n",
    "print('\\nKeys of the locations dictionary:', list(csv_locations_dictionary.keys()))\n",
    "print('Locations of the AIE station:', csv_locations_dictionary['AIE'])\n",
    "print('Locations of the AGSTE station:', csv_locations_dictionary['AGSTE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9e4a6-f150-441d-a675-bb55c1512ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Havingstored the content of the CSV files into ordered dictionaries, we can perform some \"quality of life\" changes to some entries.\n",
    "# The first thing we want to do is to convert the \"TIMESTAMP\" to a humanly readable date/time.\n",
    "\n",
    "# We start by creating an empty list, that acts as \"container\" for the converted data\n",
    "csv_measurement_time_converted = []\n",
    "# We can loop over the \"TIMESTAMP\" list within the measurement diary, and convert all its content\n",
    "for timestamp_value in csv_measurements_dictionary['TIMESTAMP']:\n",
    "    # Datetime gives us a function that converts timestamps automatically.\n",
    "    # You can read more about it here: https://docs.python.org/3/library/datetime.html#datetime.datetime.utcfromtimestamp\n",
    "    current_datetime_converted = datetime.datetime.utcfromtimestamp(timestamp_value)\n",
    "    csv_measurement_time_converted.append(current_datetime_converted)\n",
    "    \n",
    "# Finally, this list of converted times can be converted to a numpy array.\n",
    "# This step is not necessary, but if you prefer to work with numpy arrays instead of list, you can perform the conversion simply by doing:\n",
    "csv_measurement_time_converted_array = np.array(csv_measurement_time_converted)\n",
    "\n",
    "print('The first 4 entries of the converted array are:\\n', csv_measurement_time_converted_array[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba441139-4daa-46fa-9ce8-23007446bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the converted array to visualize all the measurements\n",
    "# The plot is performed similarly to the one we did for the time series of 2-meter temperature\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "\n",
    "for station_name in csv_measurements_dictionary.keys():\n",
    "    \n",
    "    if station_name == 'TIMESTAMP':\n",
    "        # Of course \"TIMESTAMP\" is not a station, we don't want to plot its value as mm of precipitation\n",
    "        continue\n",
    "    elif np.sum(np.isfinite(csv_measurements_dictionary[station_name])) == 0:\n",
    "        # We don't want to waste time trying to plot emty time series\n",
    "        continue\n",
    "    else:\n",
    "        ax.plot(csv_measurement_time_converted_array, csv_measurements_dictionary[station_name], marker='.', label=station_name)\n",
    "ax.legend()\n",
    "\n",
    "# As before, we fnish up the plot with some formatting\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Preicpitation [mm]')\n",
    "ax.set_title('Rain gauge measurements')\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(ls=':', c='gray', alpha=0.5)\n",
    "date_format_xaxis = mdates.DateFormatter('%d-%m-%Y\\n%H:%M')\n",
    "ax.xaxis.set_major_formatter(date_format_xaxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db318992-18f5-4124-9086-cb4011c19de9",
   "metadata": {},
   "source": [
    "# 4. Performing temporal averages\n",
    "\n",
    "A task that you may encounter is the computation of averages over fixed periods of times (e.g. monthly, daily, etc...)\n",
    "Here we will provide some simple code to perform an average over a fixed time window for a 1 dimensional array, using the csv data loaded in the previous section.\n",
    "If you have data in a 2-dimensional grid (like in the netCDF example), you can simply apply the same code to each pixel independently.\n",
    "\n",
    "The way in which we execute the averaging favors clarity over speed of execution.\n",
    "In case the execution is excessively slow in your application, you can try to have a look at this page for faster alternatives:\n",
    "https://stackoverflow.com/questions/13728392/moving-average-or-running-mean\n",
    "\n",
    "However, the code proposed above defines the window size in terms of indices and not in terms of \"datetime.timedelta\".\n",
    "You will have to compute the number of indices covered by your desired time window before applying the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4797cc0-9931-4176-85d5-6b1340b600d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will now define a function to perform the moving average over a fixed temporal window\n",
    "# This function will accept in input:\n",
    "# - a 1-dimensional (numpy) array containing the time associated to the data that we want to average,\n",
    "# - a 1-dimensional (numpy) array containing the data that we want to average,\n",
    "# - the size of the window as a \"datetime.timedelta\" object,\n",
    "# - an optional value for the start date/time of the averaged output\n",
    "# - an optional value for the end date/time of the averaged output\n",
    "# The last two variables are optional: if you don't provide them, the function will pick the start and end of the time array (plus/minus half the window size).\n",
    "def perform_average_over_sliding_time_window(array1d_time, array1d_measurements, window_size, optional_start_time=None, optional_end_date=None):\n",
    "    # First we check that the two arrays are indeed numpy arrays an not simply lists\n",
    "    if type(array1d_time) is list:\n",
    "        array1d_time = np.array(array1d_time)\n",
    "    if type(array1d_measurements) is list:\n",
    "        array1d_measurements = np.array(array1d_measurements)\n",
    "        \n",
    "    # To center the window around the current point, we compute the half window size\n",
    "    half_window = window_size / 2.\n",
    "    \n",
    "    # Converting the window (and half window) size to numpy\n",
    "    window_size = np.array([window_size], dtype=\"timedelta64[ms]\")[0]\n",
    "    half_window = np.array([half_window], dtype=\"timedelta64[ms]\")[0]\n",
    "\n",
    "    # If the optional start time has not been provided, we set it equal to the minimum of array1d_time\n",
    "    if optional_start_time is None:\n",
    "        optional_start_time = np.min(array1d_time) + half_window\n",
    "    # Idem for the end date (plus 1 second so we're sure we don't have problems with the \"lower than\")\n",
    "    if optional_end_date is None:\n",
    "        optional_end_date = np.max(array1d_time) - half_window + datetime.timedelta(seconds=1)\n",
    "    \n",
    "    # Converting the start/end time to numpy format\n",
    "    numpy_start_time = np.datetime64(optional_start_time)\n",
    "    numpy_end_date = np.datetime64(optional_end_date)\n",
    "\n",
    "    # Using the window size and the start time, we can define a time array to associate to the output averaged array\n",
    "    array1d_time_averaged = np.arange(optional_start_time, optional_end_date, window_size)\n",
    "    \n",
    "    # Create an empty container for the averaged field\n",
    "    array1d_measurements_averaged = np.full(array1d_time_averaged.shape, np.nan)\n",
    "    \n",
    "    # Let's loop over the time array\n",
    "    for idx_t, t_step in enumerate(array1d_time_averaged):\n",
    "        # We create a boolean array with all the points in the window\n",
    "        idx_inside_window = np.logical_and(array1d_time >= t_step - half_window, array1d_time < t_step + half_window)\n",
    "\n",
    "        # Extract measurements that are in the window\n",
    "        measurements_in_window = array1d_measurements[idx_inside_window]\n",
    "        # If any of them is a valid measurement (not a \"nan\"), we continue with the computation\n",
    "        if np.sum(np.isfinite(measurements_in_window)):\n",
    "            # We average the measurement with the \"nanmean\" function\n",
    "            array1d_measurements_averaged[idx_t] = np.nanmean(measurements_in_window)\n",
    "\n",
    "    # Finally, we return the 2 arrays: one with the averaged time, one with all averaged values\n",
    "    return array1d_time_averaged, array1d_measurements_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb1754-6c3f-4701-ba37-1b7eef5f13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us test the function with two window sizes over the \"csv_measurements_dictionary\" that we displayed in the previous section\n",
    "# We define two window sizes for the test:\n",
    "window_size_30min = datetime.timedelta(minutes=30) # 30 minutes\n",
    "window_size_60min = datetime.timedelta(hours=1) # 1 hour\n",
    "\n",
    "# Let us provide the start and end time of the averaging (same for both cases)\n",
    "start_time_averaging = datetime.datetime(2016,1,1,1,0)\n",
    "end_time_averaging = datetime.datetime(2016,1,1,3,0)\n",
    "\n",
    "# Create two empty dictionaries to contain the averaged time arrays\n",
    "csv_datetime_averaged_30min = OrderedDict()\n",
    "csv_datetime_averaged_60min = OrderedDict()\n",
    "\n",
    "# Create two empty dictionaries to contain the averaged data\n",
    "csv_measurements_averaged_30min = OrderedDict()\n",
    "csv_measurements_averaged_60min = OrderedDict()\n",
    "\n",
    "# Let's apply the averaging to all the stations with at least 1 valid measurement\n",
    "for station_name in csv_measurements_dictionary.keys():\n",
    "    if station_name == 'TIMESTAMP':\n",
    "        # Of course \"TIMESTAMP\" is not a station, we don't want to plot its value as mm of precipitation\n",
    "        continue\n",
    "    elif np.sum(np.isfinite(csv_measurements_dictionary[station_name])):\n",
    "        current_averaged_time_30min, current_averaged_measurements_30min = perform_average_over_sliding_time_window(csv_measurement_time_converted_array,\n",
    "                                                                                                                    csv_measurements_dictionary[station_name],\n",
    "                                                                                                                    window_size_30min,\n",
    "                                                                                                                    start_time_averaging,\n",
    "                                                                                                                    end_time_averaging)\n",
    "        current_averaged_time_60min, current_averaged_measurements_60min = perform_average_over_sliding_time_window(csv_measurement_time_converted_array,\n",
    "                                                                                                                    csv_measurements_dictionary[station_name],\n",
    "                                                                                                                    window_size_60min,\n",
    "                                                                                                                    start_time_averaging,\n",
    "                                                                                                                    end_time_averaging)\n",
    "        # Assiginign the array to the correct key in the dictionary\n",
    "        csv_datetime_averaged_30min[station_name] = current_averaged_time_30min\n",
    "        csv_datetime_averaged_60min[station_name] = current_averaged_time_60min\n",
    "        \n",
    "        csv_measurements_averaged_30min[station_name] = current_averaged_measurements_30min\n",
    "        csv_measurements_averaged_60min[station_name] = current_averaged_measurements_60min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a2a41-36db-407b-aa9e-1d4a1e1d3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the averaging output in a figure with three panels:\n",
    "# - the first shows the original time series\n",
    "# - the second shows the 30 minutes average\n",
    "# - the third shows the 1 hour average\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 11))\n",
    "\n",
    "# We can loop directly over the \"csv_measurements_averaged_30min\" dictionary, since it only contains stations with valid measurements\n",
    "for idx_station, station_name in enumerate(csv_measurements_averaged_30min.keys()):\n",
    "    # We assign a different name to each axis to reduce confusion\n",
    "    ax_noave = axes[0] # <- the first axis, for the original time series\n",
    "    ax_30min = axes[1] # <- the first axis, for the 30 minutes average\n",
    "    ax_60min = axes[2] # <- the first axis, for the 1 hour average\n",
    "\n",
    "    # We plot each time series on a different axis\n",
    "    ax_noave.plot(csv_measurement_time_converted_array, csv_measurements_dictionary[station_name], marker='.', label=station_name)\n",
    "    ax_30min.plot(csv_datetime_averaged_30min[station_name], csv_measurements_averaged_30min[station_name], marker='s', label=station_name)\n",
    "    ax_60min.plot(csv_datetime_averaged_60min[station_name], csv_measurements_averaged_60min[station_name], marker='^', label=station_name)\n",
    "\n",
    "    # Let's differenciate the panels with titles that briefly describe their content\n",
    "    ax_noave.set_title('Original rain gauge measurements')\n",
    "    ax_30min.set_title('Rain gauge measurements averaged over 30 minutes')\n",
    "    ax_60min.set_title('Rain gauge measurements averaged over 60 minutes')\n",
    "\n",
    "# The formatting is the same for all the axis, so we can simply loop over all of them and call all the functions\n",
    "for ax in axes:\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Preicpitation [mm]')\n",
    "    ax.set_title('Rain gauge measurements')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(ls=':', c='gray', alpha=0.5)\n",
    "    date_format_xaxis = mdates.DateFormatter('%H:%M')\n",
    "    ax.xaxis.set_major_formatter(date_format_xaxis)\n",
    "    \n",
    "    # Let us set the same limits on the y-axis to each panel, so they are easier to compare\n",
    "    ax.set_ylim((-0.02, 0.62)) # We know the values from the previous plot\n",
    "\n",
    "# We let matplotlib to figure out the optimal distance between panels/labels/etc...\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de290940-4bda-4d7c-aa18-54e28ad509c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Radar ex",
   "language": "python",
   "name": "radar_ex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
